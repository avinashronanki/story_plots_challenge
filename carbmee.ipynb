{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "carbmee.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmumHCwLKGVF"
      },
      "source": [
        "# Note:\n",
        "\n",
        "The below approaches are performed on 15 stories for demonstration purposes. Please note that this is scalable to the entire dataset as well. Full analysis is omitted due to computational limitations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQTTN17fkzYV"
      },
      "source": [
        "# Approach 1\n",
        "1. Create a list of the top ten proper nouns from each story.\n",
        "2. To identify the people on the list, see if any of these terms are followed by a verb (40 percent).\n",
        "(It's most likely a person)\n",
        "3. Words that are not followed by a verb at least 40% of the time are removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPi0uKpmdOAH"
      },
      "source": [
        "#run this cell only for colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/plots ./plots\n",
        "!cp /content/drive/MyDrive/titles ./titles\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0VqC-18o8E0"
      },
      "source": [
        "!pip install TextBlob\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogPQGetuqxnH"
      },
      "source": [
        "# first 10 stories\n",
        "stories = []\n",
        "story = \"\"\n",
        "with open('plots') as f:\n",
        "    for line in f:\n",
        "        if len(stories) == 16:\n",
        "            break\n",
        "        if '<EOS>' in line:\n",
        "          stories.append(story)\n",
        "          story = \"\"\n",
        "        else:\n",
        "          story = story + line\n",
        "stories = [story.replace(\"\\n\", \"\") for story in stories]\n",
        "stories = [story.replace(\"\\\\\", \"\") for story in stories]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XDsDLabxMi6"
      },
      "source": [
        "with open('titles') as titles_file:\n",
        "  titles = titles_file.readlines()\n",
        "titles = [title.replace(\"\\n\", \"\") for title in titles]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJPwyb_4kvfe",
        "outputId": "16b9f166-4811-4731-d238-42cb67c93761"
      },
      "source": [
        "import string\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "# nltk.download('brown')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "#clean up\n",
        "# clearingSymbols = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’‘'\n",
        "# for c in clearingSymbols:\n",
        "#     text = text.replace(c, '')\n",
        "\n",
        "for index, story in enumerate(stories):\n",
        "    blob = TextBlob(story)\n",
        "\n",
        "    verbs = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
        "    a = blob.tags  #pos tagging\n",
        "\n",
        "    # retruns the top 10 propernouns \n",
        "    def prn(plotblob):\n",
        "        d = plotblob.np_counts # noun counter \n",
        "        d = dict(d)\n",
        "        top = sorted(d, key=d.get, reverse=True)\n",
        "        return top[0:10]\n",
        "\n",
        "    dictionary = blob.np_counts\n",
        "    # checks if the noun followed by verb 50% of the time \n",
        "    for word in prn(blob):\n",
        "        count = 0\n",
        "        for i in range(0, len(a)-1):\n",
        "            if a[i][0] == word or a[i][0] == word.title():\n",
        "                if a[i+1][1] in verbs:\n",
        "                    count = count + 1\n",
        "        if count / dictionary[word] > 0.4:\n",
        "            protaganist = word \n",
        "            print(\"The protagonist of the story \" + titles[index] + \" is :-\" + protaganist) \n",
        "            break\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The protagonist of the story Animal Farm is :-napoleon\n",
            "The protagonist of the story A Clockwork Orange (novel) is :-alex\n",
            "The protagonist of the story The Plague is :-tarrou\n",
            "The protagonist of the story Actaeon is :-actaeon\n",
            "The protagonist of the story A Fire Upon the Deep is :-lab\n",
            "The protagonist of the story All Quiet on the Western Front is :-paul\n",
            "The protagonist of the story Anyone Can Whistle is :-fay\n",
            "The protagonist of the story A Funny Thing Happened on the Way to the Forum is :-senex\n",
            "The protagonist of the story Army of Darkness is :-ash\n",
            "The protagonist of the story The Birth of a Nation is :-cameron\n",
            "The protagonist of the story Blade Runner is :-deckard\n",
            "The protagonist of the story Blazing Saddles is :-bart\n",
            "The protagonist of the story Blue Velvet (film) is :-dreams\n",
            "The protagonist of the story Barry Lyndon is :-barry\n",
            "The protagonist of the story Buffy the Vampire Slayer (film) is :-pike\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd3LIV3_YRhl"
      },
      "source": [
        "# Limitation\n",
        "This approach is not ideal because it appears to be failing in some edge cases. As an example, **\"Apple purchased Mitsubishi stock, and Apple fans are overjoyed.\"** Apple is considered a noun here, which is correct, but in the context of the sentence, Apple is an organization. As a result, I have discarded this approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSD1tKUV58b0"
      },
      "source": [
        "# Approach 2\n",
        "\n",
        "This the prefered approach. It consists of: \n",
        "1. **NLTK NER classifer**, which contains a person classifier as well \n",
        "2. The protaganist is extracted by calculating the **frequency of the person occurences** in each story.\n",
        "3. **Coreference Resolution** is performed for enriching the frequency information and also to identfy the gender of the protaganist \n",
        "4. Finally, in the case where coreference resolution fails in gender identification, a **naive bayes classifer** trained on gender name data is employed to classify the protaganist gender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rSkC0Co6FXs"
      },
      "source": [
        "!pip install flair\n",
        "!pip install torch==1.9.0\n",
        "!pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
        "!pip install transformers==4.1.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoBo4CGxDdMw"
      },
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import string\n",
        "from itertools import combinations\n",
        "from collections import Counter\n",
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "from nltk.corpus import names\n",
        "from nltk import NaiveBayesClassifier as NBC\n",
        "from nltk import classify\n",
        "import random\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('names')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meiW9j_VCnrs"
      },
      "source": [
        "#training gender classifier \n",
        "\n",
        "def gender_features(word):\n",
        "    return {'last_letter': word[-1]}\n",
        "\n",
        "\n",
        "maleNames = [(name, 'male') for name in names.words('male.txt')]\n",
        "femaleNames = [(name, 'female') for name in names.words('female.txt')]\n",
        "allNames = maleNames + femaleNames\n",
        "random.shuffle(allNames)\n",
        "featureData = [(gender_features(namelist), gender)for (namelist, gender) in allNames]\n",
        "test_data = featureData[:800]\n",
        "train_data = featureData[800:]\n",
        "classifier = NBC.train(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whDizFPPlq_X"
      },
      "source": [
        "# Use flair named entity recognition\n",
        "tagger = SequenceTagger.load('ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ZvseI2fG9g"
      },
      "source": [
        "#extracting all the persons \n",
        "all_story_names = []\n",
        "for s in stories:\n",
        "  names = []\n",
        "  sent = nltk.tokenize.sent_tokenize(s)\n",
        "  # Get all the names of entities tagged as people\n",
        "  for line in tqdm(sent):\n",
        "    sentence = Sentence(line)\n",
        "    tagger.predict(sentence)\n",
        "    for entity in sentence.to_dict(tag_type='ner')['entities']:\n",
        "      if entity['labels'][0].value == 'PER':\n",
        "        names.append(entity['text'])\n",
        "  all_story_names.append(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAKUXYp6z2-t"
      },
      "source": [
        "all_story_names[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdwbE2bCjDVE"
      },
      "source": [
        "# Remove any punctuation within the names\n",
        "\n",
        "protagonists = []\n",
        "\n",
        "for story_names in all_story_names:\n",
        "  names = []\n",
        "  for name in story_names:\n",
        "    names.append(name.translate(str.maketrans('', '', string.punctuation)))\n",
        "  \n",
        "  result = [item for items, c in Counter(story_names).most_common()\n",
        "                                        for item in [items] * c]\n",
        "  #extracting the protagonist by calculating the frequency\n",
        "  protagonist =  Counter(names).most_common()[0][0]\n",
        "  protagonists.append(protagonist)\n",
        "  # print(Counter(names).most_common()) \n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qcfMQkp80G5",
        "outputId": "cf9d81e3-b548-4dd0-bdd6-111e73587324"
      },
      "source": [
        "protagonists"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Napoleon',\n",
              " 'Alex',\n",
              " 'Rieux',\n",
              " 'Artemis',\n",
              " 'Pham',\n",
              " 'Paul',\n",
              " 'Fay',\n",
              " 'Senex',\n",
              " 'Ash',\n",
              " 'Cameron',\n",
              " 'Deckard',\n",
              " 'Bart',\n",
              " 'Jeffrey',\n",
              " 'Rachael',\n",
              " 'Barry',\n",
              " 'Buffy']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D8wEZTKOCFq"
      },
      "source": [
        "### Gender identification using coreference resolution and Gender classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4l_j8BcnDQl"
      },
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "model_url = 'https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz'\n",
        "predictor = Predictor.from_path(model_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7e8F1gaq9CJ",
        "outputId": "1e5663b2-c6d1-4f59-afbe-86891fda2287"
      },
      "source": [
        "for index, protagonist in enumerate(protagonists):\n",
        "  pred = predictor.predict(\n",
        "      document=stories[index]\n",
        "  )\n",
        "  clusters = pred['clusters']\n",
        "  document = pred['document']\n",
        "\n",
        "  n = 0\n",
        "  doc = {}\n",
        "  for obj in document:\n",
        "      doc.update({n:  obj})\n",
        "      n = n+1\n",
        "# captures all the coreferenc clusters of a particular noun\n",
        "  clus_all = []\n",
        "  cluster = []\n",
        "  clus_one = {}\n",
        "  for i in range(0, len(clusters)):\n",
        "      one_cl = clusters[i]\n",
        "      for count in range(0, len(one_cl)):\n",
        "          obj = one_cl[count]\n",
        "          for num in range((obj[0]), (obj[1]+1)):\n",
        "              for n in doc:\n",
        "                  if num == n:\n",
        "                      cluster.append(doc[n])\n",
        "      clus_all.append(cluster)\n",
        "      cluster = []\n",
        "  # print(clus_all)  # And finally, this shows all coreferences\n",
        "\n",
        "\n",
        "  gender = \"na\"\n",
        "\n",
        "\n",
        "  for cluster in clus_all:\n",
        "    if protagonist in cluster:\n",
        "      cluster_lower = [word.lower() for word in cluster]\n",
        "      if \"she\" in cluster_lower or \"her\" in cluster_lower or \"hers\" in cluster_lower:\n",
        "        gender = \"female\"\n",
        "      if \"he\" in cluster_lower or \"him\" in cluster_lower or \"his\" in cluster_lower:\n",
        "        gender = \"male\"\n",
        "  \n",
        "  if gender == \"na\":\n",
        "    gender = classifier.classify(gender_features(protagonist))\n",
        "  \n",
        "  print(\"gender of protagonist \" + protagonist + \" of the story \" + titles[index] + \" is \" + gender)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gender of protagonist Napoleon of the story Animal Farm is male\n",
            "gender of protagonist Alex of the story A Clockwork Orange (novel) is male\n",
            "gender of protagonist Rieux of the story The Plague is male\n",
            "gender of protagonist Artemis of the story Actaeon is female\n",
            "gender of protagonist Pham of the story A Fire Upon the Deep is male\n",
            "gender of protagonist Paul of the story All Quiet on the Western Front is male\n",
            "gender of protagonist Fay of the story Anyone Can Whistle is female\n",
            "gender of protagonist Senex of the story A Funny Thing Happened on the Way to the Forum is male\n",
            "gender of protagonist Ash of the story Army of Darkness is male\n",
            "gender of protagonist Cameron of the story The Birth of a Nation is female\n",
            "gender of protagonist Deckard of the story Blade Runner is male\n",
            "gender of protagonist Bart of the story Blazing Saddles is male\n",
            "gender of protagonist Jeffrey of the story Blue Velvet (film) is male\n",
            "gender of protagonist Rachael of the story Blade Runner 2: The Edge of Human is male\n",
            "gender of protagonist Barry of the story Barry Lyndon is male\n",
            "gender of protagonist Buffy of the story Buffy the Vampire Slayer (film) is female\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpAoKgGhIN4P"
      },
      "source": [
        "#Improvements\n",
        "\n",
        "1. In some case antagonist might have higest frequency. A way to elminate this would be to calculate average sentiment of the sentences containing the top candidates for protagonists and selecting those with a net positive sentiment.\n",
        "2. The case of multiple protagonists in a story could be figured out by identifying the distribution of the occurences of the characters. If the distribution seems to be even, then there is a possibility of multiple or no protagonists. \n",
        "3. Creation of an external ground truth can be achieved by utilising search engine APIs, by converting the title to a question (for eg. \"Who is the protagonist of Buffy the Vampire Slayer?\") and then extracting the answer from the search engine results. In the case that search engine querying is expensive, the open source movie database TMDB can be used to capture the protagonist as well as their gender. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y6XdykFSCpS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}